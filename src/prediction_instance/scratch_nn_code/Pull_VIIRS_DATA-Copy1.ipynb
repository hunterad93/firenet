{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d992f744",
   "metadata": {},
   "source": [
    "# Processing VIIRS Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b312e8",
   "metadata": {},
   "source": [
    "The VIIRS data originates from the Fire Information for Resource Management System, which is a NASA platform that provides near real-time active fire locations across the world. This data is downloaded in the form of a csv containing the spatiotemporal location of a given fire. As such, it is point process data.\n",
    "\n",
    "In order to make use of such information, we have to turn it into pixelized raster information. As such, I modified an existing script to run it through the pipeline. This script relies on a clustering algorithm called DBSCAN, which is a method to group sets of points via their location in either geographic or feature space. The advantage of DBSCAN is that it does not need a pre-specified number of clusters (as opposed to K-means, for example). \n",
    "\n",
    "The general outline of this pipeline is as follows:\n",
    "\n",
    "- Connect to FIRMS API using a unique identifier given by NASA\n",
    "- Download all data from 2020\n",
    "- Run the rasterization algorithm on each date, first removing all daytime observations per Matt Jolly's suggestion\n",
    "- Save both the boolean labeled mask and continuous Fire Radiative Power metric to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08d15fc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seancarter/opt/miniconda3/envs/work/lib/python3.10/site-packages/geopandas/_compat.py:112: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request as request\n",
    "from datetime import datetime\n",
    "import geopandas as gpd\n",
    "import glob\n",
    "from rioxarray.merge import merge_arrays\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "from src.data_sources import cluster_fires, create_chip_bounds, fires_from_topleft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff9dd813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write loop to pull all data from 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5234d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = \"-124.848974,24.396308,-66.885444,49.384358\"\n",
    "FIRMS_API_KEY = '58ee6e88ea288308039c476b13723cb7'\n",
    "dates_2019 = pd.date_range(start='2019-01-01', end='2019-12-31').strftime('%Y-%m-%d').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1890e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_viirs_data(date_list, api_key, bbox, path):\n",
    "    '''\n",
    "    Connect with FIRMS API to access VIIRS detection data from specific dates and areas\n",
    "    \n",
    "    :param date_list: list, each date encoded in '%Y-%m-%d'\n",
    "    :param api_key: str, from NASA email\n",
    "    :param bbox: str, bbox of the region of interest\n",
    "    :param path: str, path of export location\n",
    "    '''\n",
    "    \n",
    "    base_url = 'https://firms.modaps.eosdis.nasa.gov/api/area/csv/'\n",
    "\n",
    "    for date in date_list:\n",
    "        url = f'{api_key}/VIIRS_SNPP_SP/{bbox}/1/{date}'\n",
    "        \n",
    "        fname = path + 'VIIRS_' + date + '.csv'\n",
    "        \n",
    "        request.urlretrieve(base_url + url, filename = fname)\n",
    "    \n",
    "# request.urlretrieve(f'https://firms.modaps.eosdis.nasa.gov/api/area/csv/{FIRMS_API_KEY}/VIIRS_SNPP_SP/{bbox}/1/2020-07-10', filename = 'temp/__VIIRS_2020-07-10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a674f88e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m start_date, end_date \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m, y \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-12-31\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m date_list \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mdate_range(start \u001b[38;5;241m=\u001b[39m start_date, end \u001b[38;5;241m=\u001b[39m end_date)\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m----> 8\u001b[0m \u001b[43mget_viirs_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFIRMS_API_KEY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(y \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Done.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mget_viirs_data\u001b[0;34m(date_list, api_key, bbox, path)\u001b[0m\n\u001b[1;32m     14\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapi_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/VIIRS_SNPP_SP/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbbox\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/1/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     16\u001b[0m fname \u001b[38;5;241m=\u001b[39m path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVIIRS_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m date \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/work/lib/python3.10/urllib/request.py:241\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m url_type, path \u001b[38;5;241m=\u001b[39m _splittype(url)\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m    242\u001b[0m     headers \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/work/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/work/lib/python3.10/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/work/lib/python3.10/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/work/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/work/lib/python3.10/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/work/lib/python3.10/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m         \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/work/lib/python3.10/http/client.py:1282\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m{}, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   1280\u001b[0m             encode_chunked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1282\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/work/lib/python3.10/http/client.py:1328\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(body, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;66;03m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;66;03m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1328\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/work/lib/python3.10/http/client.py:1277\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1277\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/work/lib/python3.10/http/client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1035\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1037\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1040\u001b[0m \n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1043\u001b[0m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/work/lib/python3.10/http/client.py:975\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/work/lib/python3.10/http/client.py:1447\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1447\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1449\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m   1450\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/work/lib/python3.10/http/client.py:941\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;124;03m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[39;00m\n\u001b[1;32m    940\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[0;32m--> 941\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/work/lib/python3.10/socket.py:833\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[1;32m    832\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m--> 833\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[1;32m    835\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "years = ['2010','2011','2012']\n",
    "for y in years:\n",
    "    export_path = y + '/'\n",
    "    start_date, end_date = y + '-01-01', y + '-12-31'\n",
    "    \n",
    "    date_list = pd.date_range(start = start_date, end = end_date).strftime('%Y-%m-%d').tolist()\n",
    "    \n",
    "    get_viirs_data(date_list, FIRMS_API_KEY, bbox, export_path)\n",
    "    \n",
    "    print(y + ' Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4726665",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_date_time(df):\n",
    "    date = df['acq_date']\n",
    "    hour = [str(h) for h in pd.to_datetime(df['acq_time'], format = '%H%M').dt.hour]\n",
    "    \n",
    "    df['acq_date_hour'] = [d + '_' + h for d,h in zip(list(date), hour)]\n",
    "    return df\n",
    "\n",
    "def process_viirs(csv_list, export_path):\n",
    "    i = 0\n",
    "    string = '='\n",
    "    \n",
    "    mod = np.floor(len(csv_list) / 100)\n",
    "    \n",
    "    for each_csv in csv_list:\n",
    "        \n",
    "        data = pd.read_csv(each_csv)\n",
    "        \n",
    "        if data.empty == True:\n",
    "            continue\n",
    "\n",
    "        # Filter by night time\n",
    "#         data = data[data.daynight == 'N']\n",
    "        \n",
    "        # Create \"clusterable\" date, hour column\n",
    "        data = create_date_time(data)\n",
    "        \n",
    "        gdf = gpd.GeoDataFrame(\n",
    "                data, geometry=gpd.points_from_xy(data.longitude, data.latitude), crs=\"EPSG:4326\") \n",
    "   \n",
    "        clustered_fires = cluster_fires(gdf, min_cluster_points=25, timescale = 'hour')\n",
    "        \n",
    "                \n",
    "        if not isinstance(clustered_fires, pd.DataFrame):\n",
    "            continue\n",
    "            \n",
    "        chip_bounds = create_chip_bounds(clustered_fires)\n",
    "    \n",
    "        fires_from_topleft(chip_bounds,  gdf, \n",
    "                           fname_suffix = '_Num', path = str(export_path + 'bool/'),\n",
    "                           export = True, variable = 'bool', return_merged = False)\n",
    "        \n",
    "        # Also export frp\n",
    "        fires_from_topleft(chip_bounds, gdf, \n",
    "                           fname_suffix = '_Num', path = str(export_path + 'frp/'),\n",
    "                           export = True, variable = 'frp', return_merged = False)\n",
    "        \n",
    "        if i % mod == 0:\n",
    "            string += \"=\"\n",
    "            print(string)\n",
    "            \n",
    "            if len(string) >= 115:\n",
    "                string = ''\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165c07aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mRasterized\u001b[m\u001b[m \u001b[34mRaw\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('../Data/Training/VIIRS')\n",
    "\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f00576",
   "metadata": {},
   "source": [
    "The new algorithm does not make variable sizes\n",
    "- Multiple fires still occur within one single raster image\n",
    "- Unclear what Chip Bounds is doing\n",
    "- THINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c254d4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "??fires_from_topleft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17c46016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==\n",
      "===\n",
      "====\n",
      "=====\n",
      "======\n",
      "=======\n",
      "========\n",
      "=========\n",
      "==========\n",
      "===========\n",
      "============\n",
      "=============\n",
      "==============\n",
      "===============\n",
      "================\n",
      "=================\n",
      "==================\n",
      "===================\n",
      "====================\n",
      "=====================\n",
      "======================\n",
      "=======================\n",
      "========================\n",
      "=========================\n",
      "==========================\n",
      "===========================\n",
      "============================\n",
      "=============================\n",
      "==============================\n",
      "===============================\n",
      "================================\n",
      "=================================\n",
      "==================================\n",
      "===================================\n",
      "====================================\n",
      "=====================================\n",
      "======================================\n",
      "=======================================\n",
      "========================================\n",
      "=========================================\n",
      "==========================================\n",
      "===========================================\n",
      "============================================\n",
      "=============================================\n",
      "==============================================\n",
      "===============================================\n",
      "================================================\n",
      "=================================================\n",
      "==================================================\n",
      "===================================================\n",
      "====================================================\n",
      "=====================================================\n",
      "======================================================\n",
      "=======================================================\n",
      "========================================================\n",
      "=========================================================\n",
      "==========================================================\n",
      "===========================================================\n",
      "============================================================\n",
      "=============================================================\n",
      "==============================================================\n",
      "===============================================================\n",
      "================================================================\n",
      "=================================================================\n",
      "==================================================================\n",
      "===================================================================\n",
      "====================================================================\n",
      "=====================================================================\n",
      "======================================================================\n",
      "=======================================================================\n",
      "========================================================================\n",
      "=========================================================================\n",
      "==========================================================================\n",
      "===========================================================================\n",
      "============================================================================\n",
      "=============================================================================\n",
      "==============================================================================\n",
      "===============================================================================\n",
      "================================================================================\n",
      "=================================================================================\n",
      "==================================================================================\n",
      "===================================================================================\n",
      "====================================================================================\n",
      "=====================================================================================\n",
      "======================================================================================\n",
      "=======================================================================================\n",
      "========================================================================================\n",
      "=========================================================================================\n",
      "==========================================================================================\n",
      "===========================================================================================\n",
      "============================================================================================\n",
      "=============================================================================================\n",
      "==============================================================================================\n",
      "===============================================================================================\n",
      "================================================================================================\n",
      "=================================================================================================\n",
      "==================================================================================================\n",
      "===================================================================================================\n",
      "====================================================================================================\n",
      "=====================================================================================================\n",
      "======================================================================================================\n",
      "=======================================================================================================\n",
      "========================================================================================================\n",
      "=========================================================================================================\n",
      "==========================================================================================================\n",
      "===========================================================================================================\n",
      "============================================================================================================\n",
      "=============================================================================================================\n",
      "==============================================================================================================\n",
      "===============================================================================================================\n",
      "================================================================================================================\n",
      "=================================================================================================================\n",
      "==================================================================================================================\n",
      "===================================================================================================================\n",
      "=\n",
      "==\n",
      "===\n",
      "====\n",
      "=====\n",
      "======\n",
      "=======\n",
      "========\n",
      "=========\n",
      "==========\n",
      "===========\n",
      "============\n",
      "=============\n",
      "==============\n",
      "===============\n",
      "================\n",
      "=================\n",
      "==================\n",
      "===================\n",
      "====================\n",
      "=====================\n",
      "======================\n",
      "=======================\n",
      "========================\n",
      "=========================\n",
      "==========================\n",
      "===========================\n",
      "============================\n",
      "=============================\n",
      "==============================\n",
      "===============================\n",
      "================================\n",
      "=================================\n",
      "==================================\n",
      "===================================\n",
      "====================================\n",
      "=====================================\n",
      "======================================\n",
      "=======================================\n",
      "========================================\n",
      "=========================================\n",
      "==========================================\n",
      "===========================================\n",
      "============================================\n",
      "=============================================\n",
      "==============================================\n",
      "===============================================\n",
      "================================================\n",
      "=================================================\n",
      "==================================================\n",
      "===================================================\n",
      "====================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "======================================================\n",
      "=======================================================\n",
      "========================================================\n",
      "=========================================================\n",
      "==========================================================\n",
      "===========================================================\n",
      "============================================================\n",
      "=============================================================\n",
      "==============================================================\n",
      "===============================================================\n",
      "================================================================\n",
      "=================================================================\n",
      "==================================================================\n",
      "===================================================================\n",
      "====================================================================\n",
      "=====================================================================\n",
      "======================================================================\n",
      "=======================================================================\n",
      "========================================================================\n",
      "=========================================================================\n",
      "==========================================================================\n",
      "===========================================================================\n",
      "============================================================================\n",
      "=============================================================================\n",
      "==============================================================================\n",
      "===============================================================================\n",
      "================================================================================\n",
      "=================================================================================\n",
      "==================================================================================\n",
      "===================================================================================\n",
      "====================================================================================\n",
      "=====================================================================================\n",
      "======================================================================================\n",
      "=======================================================================================\n",
      "========================================================================================\n",
      "=========================================================================================\n",
      "==========================================================================================\n",
      "===========================================================================================\n",
      "============================================================================================\n",
      "=============================================================================================\n",
      "==============================================================================================\n",
      "===============================================================================================\n",
      "================================================================================================\n",
      "=================================================================================================\n",
      "==================================================================================================\n",
      "===================================================================================================\n",
      "====================================================================================================\n",
      "=====================================================================================================\n",
      "======================================================================================================\n",
      "=======================================================================================================\n",
      "========================================================================================================\n",
      "=========================================================================================================\n",
      "==========================================================================================================\n",
      "===========================================================================================================\n",
      "============================================================================================================\n",
      "=============================================================================================================\n",
      "==============================================================================================================\n",
      "===============================================================================================================\n",
      "================================================================================================================\n",
      "=================================================================================================================\n",
      "==================================================================================================================\n",
      "===================================================================================================================\n",
      "=\n",
      "==\n",
      "===\n",
      "====\n",
      "=====\n",
      "======\n",
      "=======\n",
      "========\n",
      "=========\n",
      "==========\n",
      "===========\n",
      "============\n",
      "=============\n",
      "==============\n",
      "===============\n",
      "================\n",
      "=================\n",
      "==================\n",
      "===================\n",
      "====================\n",
      "=====================\n",
      "======================\n",
      "=======================\n",
      "========================\n",
      "=========================\n",
      "==========================\n",
      "===========================\n",
      "============================\n",
      "=============================\n",
      "==============================\n",
      "===============================\n",
      "================================\n",
      "=================================\n",
      "==================================\n",
      "===================================\n",
      "====================================\n",
      "=====================================\n",
      "======================================\n",
      "=======================================\n",
      "========================================\n",
      "=========================================\n",
      "==========================================\n",
      "===========================================\n",
      "============================================\n",
      "=============================================\n",
      "==============================================\n",
      "===============================================\n",
      "================================================\n",
      "=================================================\n",
      "==================================================\n",
      "===================================================\n",
      "====================================================\n",
      "=====================================================\n",
      "======================================================\n",
      "=======================================================\n",
      "========================================================\n",
      "=========================================================\n",
      "==========================================================\n",
      "===========================================================\n",
      "============================================================\n",
      "=============================================================\n",
      "==============================================================\n",
      "===============================================================\n",
      "================================================================\n",
      "=================================================================\n",
      "==================================================================\n",
      "===================================================================\n",
      "====================================================================\n",
      "=====================================================================\n",
      "======================================================================\n",
      "=======================================================================\n",
      "========================================================================\n",
      "=========================================================================\n",
      "==========================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "============================================================================\n",
      "=============================================================================\n",
      "==============================================================================\n",
      "===============================================================================\n",
      "================================================================================\n",
      "=================================================================================\n",
      "==================================================================================\n",
      "===================================================================================\n",
      "====================================================================================\n",
      "=====================================================================================\n",
      "======================================================================================\n",
      "=======================================================================================\n",
      "========================================================================================\n",
      "=========================================================================================\n",
      "==========================================================================================\n",
      "===========================================================================================\n",
      "============================================================================================\n",
      "=============================================================================================\n",
      "==============================================================================================\n",
      "===============================================================================================\n",
      "================================================================================================\n",
      "=================================================================================================\n",
      "==================================================================================================\n",
      "===================================================================================================\n",
      "====================================================================================================\n",
      "=====================================================================================================\n",
      "======================================================================================================\n",
      "=======================================================================================================\n",
      "========================================================================================================\n",
      "=========================================================================================================\n",
      "==========================================================================================================\n",
      "===========================================================================================================\n",
      "============================================================================================================\n",
      "=============================================================================================================\n",
      "==============================================================================================================\n",
      "===============================================================================================================\n",
      "================================================================================================================\n",
      "=================================================================================================================\n",
      "==================================================================================================================\n",
      "===================================================================================================================\n",
      "=\n",
      "==\n",
      "===\n",
      "====\n",
      "=====\n",
      "======\n",
      "=======\n",
      "========\n",
      "=========\n",
      "==========\n",
      "===========\n",
      "============\n",
      "=============\n",
      "==============\n",
      "===============\n",
      "================\n",
      "=================\n",
      "==================\n",
      "===================\n",
      "====================\n",
      "2021 Done.\n"
     ]
    }
   ],
   "source": [
    "years = ['2021']\n",
    "    \n",
    "    #'2017','2018','2019', '2020', \n",
    "for y in years:\n",
    "    csv_list = glob.glob('Raw/' + y + '/*.csv')\n",
    "    \n",
    "    export_path = 'Rasterized/Individual_Fires/variable_size/' + y + '/'\n",
    "    if not os.path.exists(export_path):\n",
    "        os.mkdir(export_path)\n",
    "        \n",
    "    process_viirs(csv_list, export_path = export_path)\n",
    "    \n",
    "    print(y + ' Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3dc39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01f8dff8",
   "metadata": {},
   "source": [
    "It appears, from examining the export directory, that the pipeline is not exporting the correct data. My hunch is that the output list encompasses more than just one date / hour observational event. From the above print statement, I see that, for example, 2017-08-05 has 5 observations at 8 AM (which is another bug),and 5 observations at 10AM.\n",
    "\n",
    "Need to:\n",
    "- Examine a sample VIIRS csv to see when the observation was made, shouldn't this be only nighttime observations??\n",
    "- Perhaps modify the original Satellite VU fires_from_topleft function to export each individual fire as a separate TIF\n",
    "- Run through my modified fires_from_topleft algorithm, step by step, to see what I'm actually doing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2689850f",
   "metadata": {},
   "source": [
    "Checking the length of the resultant training images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67f8ccdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2012\u001b[m\u001b[m \u001b[34m2013\u001b[m\u001b[m \u001b[34m2014\u001b[m\u001b[m \u001b[34m2015\u001b[m\u001b[m \u001b[34m2016\u001b[m\u001b[m \u001b[34m2017\u001b[m\u001b[m \u001b[34m2018\u001b[m\u001b[m \u001b[34m2019\u001b[m\u001b[m \u001b[34m2020\u001b[m\u001b[m \u001b[34m2021\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../Rasterized/COG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4658955f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d87b237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461e688c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1311c953",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012: 304\n",
      "2013: 184\n",
      "2014: 194\n",
      "2015: 161\n",
      "2016: 167\n",
      "2017: 307\n",
      "2018: 202\n",
      "2019: 68\n",
      "2020: 291\n",
      "2021: 251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2129"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 0\n",
    "for year in range(2012,2022):\n",
    "    \n",
    "    length =  len(glob.glob('../Rasterized/COG/' + str(year) + '/bool/*.tif'))\n",
    "    print(str(year) + ': ' + str(length))\n",
    "    x += length\n",
    "    \n",
    "    \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4007944a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1878"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9acbd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(glob.glob('../Data/Training/VIIRS/Rasterized/2021/bool/*.nc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc91d84",
   "metadata": {},
   "source": [
    "Total of about 500 images, might not be enough to train the UNET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14698e",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde9a0ca",
   "metadata": {},
   "source": [
    "Modifying fires_from_topleft to export a separate tif for each fire, rather than all fires in CONUS within a given day/ hour time frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f769108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified - it will export each individual fire\n",
    "def fires_from_topleft(chip_bounds, fires, fname_suffix = '', \n",
    "                       export = False, path = '', variable = 'bool',\n",
    "                       return_merged = True):\n",
    "    \"\"\"\n",
    "    Given input chip DataFrame, link with raw VIIRS input to receive FRP,\n",
    "            rasterizing the points\n",
    "    \n",
    "    :param chip_bounds: pandas DF containing each chip bound\n",
    "    :param fires: gpd.GeoDataFrame or filename of original VIIRS data\n",
    "    :param fname_suffix: str, indicates the suffix for the filename\n",
    "    :param export: Bool, indicates whether to export or to return the list\n",
    "    :param path: str, indicates path of export location\n",
    "    :param variable: Str, either \"bool\" or \"frp\", indicates whether to export\n",
    "            the boolean mask or a continuous measurement of fire radiative power\n",
    "    :param return_merged: Bool, indicates whether to export all fires in CONUS within a given\n",
    "            day/hour time frame, or to export each individual fire as a separate TIF\n",
    "    :return: list of xarray.Datasets which each contain a raster that indicates multiple \n",
    "            fires for each date\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract each date where there was an observation\n",
    "    list_of_dates = chip_bounds.date.unique()\n",
    "    \n",
    "    # Define output list\n",
    "    output_list = []\n",
    "    \n",
    "    for each_date in list_of_dates:\n",
    "        # Reset output every day to get a new raster each date\n",
    "        output_raster_img = None\n",
    "        \n",
    "        samples_in_that_day = chip_bounds[chip_bounds['date'] == each_date]\n",
    "        \n",
    "        # Grab bounding box for each sample\n",
    "        for _, sample in samples_in_that_day.iterrows():\n",
    "            \n",
    "            top_left = [sample['top'],sample['left']]\n",
    "            epsg_code = str(sample['epsg'])\n",
    "            date_to_query = sample['date']\n",
    "                                        \n",
    "                                       \n",
    "    \n",
    "            aoi = bounds_to_geojson(\n",
    "                rasterio.coords.BoundingBox(\n",
    "                    left=top_left[1],\n",
    "                    right=top_left[1] + 32000,\n",
    "                    bottom=top_left[0] - 32000,\n",
    "                    top=top_left[0],\n",
    "                )\n",
    "            )\n",
    "        \n",
    "            # reproj the bbox from utm to 4326\n",
    "            utm_to_wgs84_transformer = pyproj.Transformer.from_crs(\n",
    "                epsg_code, 4326, always_xy=True\n",
    "            ).transform\n",
    "            aoi_wgs84 = shapely_tf(utm_to_wgs84_transformer, shape(aoi))\n",
    "\n",
    "            # load fire data intersecting chip bbox\n",
    "            # --> Loads a gpd file for each sample, super inefficient, could be improved\n",
    "\n",
    "            if isinstance(fires, str):\n",
    "                fires_in_chip = gpd.read_file(fires, layer=\"merge\", bbox=aoi_wgs84)\n",
    "            else:\n",
    "                chip_poly = gpd.GeoDataFrame(geometry=[aoi_wgs84], crs=\"EPSG:4326\")\n",
    "                fires_in_chip = fires[fires[\"acq_date\"] == date_to_query].clip(chip_poly)\n",
    "\n",
    "            fires_in_chip = fires_in_chip[fires_in_chip[\"acq_date\"] == date_to_query]\n",
    "\n",
    "            if fires_in_chip.empty:\n",
    "                # possible if fire dies \"next day\"\n",
    "                fires_in_chip = gpd.GeoDataFrame(geometry=[aoi_wgs84.centroid], crs=\"EPSG:4326\")\n",
    "                fires_in_chip[\"bool\"] = 0\n",
    "                fires_in_chip[\"frp\"] = 0\n",
    "            else:\n",
    "                fires_in_chip[\"bool\"] = 1\n",
    "                fires_in_chip[\"frp\"] = pd.to_numeric(fires_in_chip[\"frp\"])\n",
    "\n",
    "            bbox_4326, utm_crs = buffer_point(\n",
    "                aoi_wgs84.centroid, buffer_m=15750, output_4326=True\n",
    "            )\n",
    "            bbox_4326_geojson = json.dumps(mapping(transform(lambda x, y: (y, x), bbox_4326)))\n",
    "\n",
    "            # Reproject fires_in_chip to GOES CRS\n",
    "            fires_in_chip = fires_in_chip.to_crs('EPSG:4326')\n",
    "            \n",
    "\n",
    "            # If output_raster_img is empty (i.e., new date)\n",
    "            if output_raster_img is None:\n",
    "                \n",
    "                # rasterize\n",
    "                output_raster_img = make_geocube(\n",
    "                    vector_data=fires_in_chip,\n",
    "                    measurements=[\"bool\", \"frp\"],\n",
    "                    resolution=(-500, 500),\n",
    "                    output_crs=str(sample['epsg']),\n",
    "                    fill=0,\n",
    "                    geom=bbox_4326_geojson,\n",
    "                )\n",
    "                \n",
    "                # Reproject to 4326\n",
    "                output_raster_img = output_raster_img.rio.reproject(\"EPSG:4326\")\n",
    "                \n",
    "                \n",
    "            # Embedd raster with date info\n",
    "            output_raster_img.attrs = {'date': each_date}\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        if export == True:\n",
    "            \n",
    "            if return_merged == True:\n",
    "                if variable == \"bool\":\n",
    "                    output_list.append(output_raster_img.bool)\n",
    "\n",
    "                else: \n",
    "                    output_list.append(output_raster_img.frp)\n",
    "\n",
    "                merged_arrays = merge_arrays(output_list, crs = \"EPSG:4326\", nodata = np.nan)\n",
    "                merged_arrays.attrs = {}\n",
    "                merged_arrays.to_netcdf(path + \"VIIRS_Rasterized\" + str(each_date) + fname_suffix + '.nc')\n",
    "                \n",
    "            elif return_merged == False:\n",
    "                num_fires = 1\n",
    "                \n",
    "                if variable == \"bool\":\n",
    "                    fname_suffix  = 'number' + str(num_fires) + fname_suffix\n",
    "                    output = output_raster_img.bool\n",
    "                    output.attrs = {}\n",
    "                    output.to_netcdf(path + \"VIIRS_Rasterized\" + str(each_date) + fname_suffix + '.nc')\n",
    "\n",
    "                else: \n",
    "                    fname_suffix  = 'number' + str(num_fires) + fname_suffix\n",
    "                    output = output_raster_img.frp\n",
    "                    output.attrs = {}\n",
    "                    output.to_netcdf(path + \"VIIRS_Rasterized\" + str(each_date) + fname_suffix + '.nc')\n",
    "                \n",
    "        \n",
    "\n",
    "            \n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81a244e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original, it merges every fire from a day/hour pair into one big raster\n",
    "def fires_from_topleft(chip_bounds, fires, fname_suffix = '', export = False, path = '', variable = 'bool'):\n",
    "    \"\"\"\n",
    "    Given input chip DataFrame, link with raw VIIRS input to receive FRP,\n",
    "            rasterizing the points\n",
    "    \n",
    "    :param chip_bounds: pandas DF containing each chip bound\n",
    "    :param fires: gpd.GeoDataFrame or filename of original VIIRS data\n",
    "    :param fname_suffix: str, indicates the suffix for the filename\n",
    "    :param export: Bool, indicates whether to export or to return the list\n",
    "    :param path: str, indicates path of export location\n",
    "    :param variable: Str, either \"bool\" or \"frp\", indicates whether to export\n",
    "            the boolean mask or a continuous measurement of fire radiative power\n",
    "    :return: list of xarray.Datasets which each contain a raster that indicates multiple \n",
    "            fires for each date\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract each date where there was an observation\n",
    "    list_of_dates = chip_bounds.date.unique()\n",
    "    \n",
    "    # Define output list\n",
    "    output_list = []\n",
    "    \n",
    "    for each_date in list_of_dates:\n",
    "        # Reset output every day to get a new raster each date\n",
    "        output_raster_img = None\n",
    "        \n",
    "        samples_in_that_day = chip_bounds[chip_bounds['date'] == each_date]\n",
    "        \n",
    "        # Grab bounding box for each sample\n",
    "        for _, sample in samples_in_that_day.iterrows():\n",
    "            \n",
    "            top_left = [sample['top'],sample['left']]\n",
    "            epsg_code = str(sample['epsg'])\n",
    "            date_to_query = sample['date']\n",
    "                                        \n",
    "                                       \n",
    "    \n",
    "            aoi = bounds_to_geojson(\n",
    "                rasterio.coords.BoundingBox(\n",
    "                    left=top_left[1],\n",
    "                    right=top_left[1] + 32000,\n",
    "                    bottom=top_left[0] - 32000,\n",
    "                    top=top_left[0],\n",
    "                )\n",
    "            )\n",
    "        \n",
    "            # reproj the bbox from utm to 4326\n",
    "            utm_to_wgs84_transformer = pyproj.Transformer.from_crs(\n",
    "                epsg_code, 4326, always_xy=True\n",
    "            ).transform\n",
    "            aoi_wgs84 = shapely_tf(utm_to_wgs84_transformer, shape(aoi))\n",
    "\n",
    "            # load fire data intersecting chip bbox\n",
    "            # --> Loads a gpd file for each sample, super inefficient, could be improved\n",
    "\n",
    "            if isinstance(fires, str):\n",
    "                fires_in_chip = gpd.read_file(fires, layer=\"merge\", bbox=aoi_wgs84)\n",
    "            else:\n",
    "                chip_poly = gpd.GeoDataFrame(geometry=[aoi_wgs84], crs=\"EPSG:4326\")\n",
    "                fires_in_chip = fires[fires[\"acq_date\"] == date_to_query].clip(chip_poly)\n",
    "\n",
    "            fires_in_chip = fires_in_chip[fires_in_chip[\"acq_date\"] == date_to_query]\n",
    "\n",
    "            if fires_in_chip.empty:\n",
    "                # possible if fire dies \"next day\"\n",
    "                fires_in_chip = gpd.GeoDataFrame(geometry=[aoi_wgs84.centroid], crs=\"EPSG:4326\")\n",
    "                fires_in_chip[\"bool\"] = 0\n",
    "                fires_in_chip[\"frp\"] = 0\n",
    "            else:\n",
    "                fires_in_chip[\"bool\"] = 1\n",
    "                fires_in_chip[\"frp\"] = pd.to_numeric(fires_in_chip[\"frp\"])\n",
    "\n",
    "            bbox_4326, utm_crs = buffer_point(\n",
    "                aoi_wgs84.centroid, buffer_m=15750, output_4326=True\n",
    "            )\n",
    "            bbox_4326_geojson = json.dumps(mapping(transform(lambda x, y: (y, x), bbox_4326)))\n",
    "\n",
    "            # Reproject fires_in_chip to GOES CRS\n",
    "            fires_in_chip = fires_in_chip.to_crs('EPSG:4326')\n",
    "            \n",
    "\n",
    "            # If output_raster_img is empty (i.e., new date)\n",
    "            if output_raster_img is None:\n",
    "                \n",
    "                # rasterize\n",
    "                output_raster_img = make_geocube(\n",
    "                    vector_data=fires_in_chip,\n",
    "                    measurements=[\"bool\", \"frp\"],\n",
    "                    resolution=(-500, 500),\n",
    "                    output_crs=str(sample['epsg']),\n",
    "                    fill=0,\n",
    "                    geom=bbox_4326_geojson,\n",
    "                )\n",
    "                \n",
    "                # Reproject to 4326\n",
    "                output_raster_img = output_raster_img.rio.reproject(\"EPSG:4326\")\n",
    "                \n",
    "                \n",
    "            # Embedd raster with date info\n",
    "            output_raster_img.attrs = {'date': each_date}\n",
    "\n",
    "        \n",
    "        if variable == \"bool\":\n",
    "            output_list.append(output_raster_img.bool)\n",
    "        \n",
    "        else: \n",
    "            output_list.append(output_raster_img.frp)\n",
    "      \n",
    "    \n",
    "        if export == True:\n",
    "            \n",
    "            merged_arrays = merge_arrays(output_list, crs = \"EPSG:4326\", nodata = np.nan)\n",
    "            merged_arrays.attrs = {}\n",
    "            merged_arrays.to_netcdf(path + \"VIIRS_Rasterized\" + str(each_date) + fname_suffix + '.nc')\n",
    "            \n",
    "            \n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d571d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks for the effect of cluster size on the output training label\n",
    "## Might not work after modifying fires_from_topleft, but would be easy to change.\n",
    "\n",
    "# for num_points in [5,10,15,20,25]:\n",
    "#     clustered_fires = cluster_fires(gdf, min_cluster_points=num_points)\n",
    "#     chip_bounds = create_chip_bounds(clustered_fires)\n",
    "#     clustered_fires.to_file('temp/clustered_fires_' + str(num_points) + '_points.shp')\n",
    "    \n",
    "#     chip_bounds = chip_bounds.reset_index()\n",
    "    \n",
    "#     for _, sample in chip_bounds.iterrows():\n",
    "#         fires = fires_from_topleft([sample['top'], \n",
    "#                             sample['left']], \n",
    "#                            str(sample['epsg']), \n",
    "#                            sample['date'],\n",
    "#                            gdf)\n",
    "        \n",
    "#         fires.to_netcdf(\"temp/fires_saved_\" + str(num_points) + '_points.nc')\n",
    "        \n",
    "#     print(\"_______NEXT_______\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
