{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fsspec\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import geojson\n",
    "from google.cloud import storage\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##functions for selecting which data to download\n",
    "\n",
    "def get_blob_names(attime=datetime.utcnow(), within=\"1H\", bucket_name='gcp-public-data-goes-16'):\n",
    "    \"\"\"\n",
    "    This function returns a list of blob names given parameters. It selects the blobs that were created within a time\n",
    "    range. The blob names can be passed to a function that selects the blobs that form complete images.\n",
    "    \"\"\"\n",
    "    if isinstance(attime, str):\n",
    "        attime = pd.to_datetime(attime)\n",
    "    if isinstance(within, str):\n",
    "        within = pd.to_timedelta(within)\n",
    "\n",
    "    # Parameter Setup\n",
    "    start = attime - within\n",
    "    end = attime + within\n",
    "\n",
    "    # Set up Google Cloud Storage client\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "\n",
    "    # Create a range of directories to check. The GOES bucket is\n",
    "    # organized by hour of day.\n",
    "    blob_names = []\n",
    "    current_time = start\n",
    "    while current_time <= end:\n",
    "        prefix = f'ABI-L2-CMIPC/{current_time.year}/{current_time.timetuple().tm_yday:03d}/{current_time.hour:02d}/'\n",
    "        blobs = bucket.list_blobs(prefix=prefix)\n",
    "        blob_names.extend([blob.name for blob in blobs])\n",
    "        current_time += timedelta(hours=1)  # Increment current_time by 1 hour\n",
    "\n",
    "    return blob_names\n",
    "\n",
    "def extract_band_number(blob_name):\n",
    "    \"\"\"\n",
    "    Extracts the band number from a blob name.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(blob_name.split('_')[1][-2:])\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def find_sequences(blob_names, unique_band_numbers):\n",
    "    \"\"\"\n",
    "    Finds the last 12 continuous sequences that match the expected band order.\n",
    "    \"\"\"\n",
    "    selected_sequences = []\n",
    "    for i in range(len(blob_names) - len(unique_band_numbers) + 1):\n",
    "        selected = blob_names[i:i+len(unique_band_numbers)]\n",
    "        band_order = [extract_band_number(name) for name in selected]\n",
    "        if band_order == unique_band_numbers:\n",
    "            selected_sequences.append(selected)\n",
    "            if len(selected_sequences) == 12:\n",
    "                break\n",
    "    return selected_sequences\n",
    "\n",
    "def select_blobs(blob_names):\n",
    "    \"\"\"\n",
    "    Selects the blobs that form complete images.\n",
    "    \"\"\"\n",
    "    # Sort blob names by timestamp\n",
    "    blob_names.sort(key=lambda name: name.split('_')[3][1:], reverse=True)\n",
    "\n",
    "    # Extract band numbers from blob names\n",
    "    band_numbers = [extract_band_number(name) for name in blob_names]\n",
    "\n",
    "    # Get unique band numbers and sort them\n",
    "    unique_band_numbers = sorted(set(band_numbers))\n",
    "\n",
    "    # Find the last 12 continuous sequences that match the expected band order\n",
    "    selected_sequences = find_sequences(blob_names, unique_band_numbers)\n",
    "\n",
    "    if len(selected_sequences) < 12:\n",
    "        raise Exception(f\"Only {len(selected_sequences)} continuous sequences found that match the expected band order\")\n",
    "\n",
    "    return selected_sequences\n",
    "\n",
    "##Downloading function\n",
    "\n",
    "def get_datasets(selected_sequences, fs, bucket_name='gcp-public-data-goes-16'):\n",
    "\n",
    "    \"\"\"\n",
    "    This function downloads datasets based on the selected sequences blob names.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a list to store dictionaries of datasets for each sequence\n",
    "    datasets = []\n",
    "\n",
    "    # Iterate over each sequence in selected_sequences\n",
    "    for sequence in selected_sequences:\n",
    "        # Initialize a dictionary to store datasets for the current sequence\n",
    "        sequence_datasets = {}\n",
    "\n",
    "        # Open each blob in the sequence as an xarray Dataset and store it in the dictionary under the corresponding channel identifier\n",
    "        for name in sequence:\n",
    "            channel_id = name.split('_')[1]\n",
    "            f = fs.open(f'{bucket_name}/{name}')\n",
    "            ds = xr.open_dataset(f, engine='h5netcdf')\n",
    "            sequence_datasets[channel_id] = ds\n",
    "\n",
    "        # Append the dictionary of datasets for the current sequence to the list of all sequences' datasets\n",
    "        datasets.append(sequence_datasets)\n",
    "\n",
    "    # Return the list of dictionaries of datasets\n",
    "    return datasets\n",
    "\n",
    "##Processing functions\n",
    "\n",
    "def form_multiband_images(datasets):\n",
    "    \"\"\"\n",
    "    This function forms complete multi-band images from a list of dictionaries of xarray Datasets.\n",
    "    Each dictionary should correspond to a sequence of blobs, with keys being the channel identifiers\n",
    "    and values being the corresponding Datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a list to store the multi-band images\n",
    "    multiband_images = []\n",
    "\n",
    "    # Iterate over each dictionary of Datasets\n",
    "    for sequence_datasets in datasets:\n",
    "        # Get the Datasets in the order of the channel identifiers\n",
    "        ordered_datasets = [sequence_datasets[channel_id] for channel_id in sorted(sequence_datasets.keys())]\n",
    "\n",
    "        # Concatenate the Datasets along a new 'band' dimension\n",
    "        multiband_image = xr.concat(ordered_datasets, dim='band')\n",
    "\n",
    "        # Append the multi-band image to the list\n",
    "        multiband_images.append(multiband_image)\n",
    "\n",
    "    # Return the list of multi-band images\n",
    "    return multiband_images\n",
    "\n",
    "def create_hourly_composite(multiband_images):\n",
    "    \"\"\"\n",
    "    This function creates an hourly composite image from a list of multi-band images.\n",
    "    Each multi-band image should correspond to a 5-minute interval.\n",
    "    \"\"\"\n",
    "\n",
    "    # Concatenate the multi-band images along a new 'time' dimension\n",
    "    hourly_images = xr.concat(multiband_images, dim='time')\n",
    "\n",
    "    # Compute the median for each band over the 'time' dimension\n",
    "    hourly_composite = hourly_images.median(dim='time')\n",
    "\n",
    "    # Return the hourly composite image\n",
    "    return hourly_composite\n",
    "\n",
    "def combine_arrays_from_composite(composite):\n",
    "    \"\"\"\n",
    "    This function combines the underlying numpy arrays from an xarray Dataset into a single numpy array.\n",
    "    It assumes that all the variables in the Dataset represent bands of the same image and can be stacked together.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a list to store the numpy arrays\n",
    "    arrays = []\n",
    "\n",
    "    # Iterate over each variable in the Dataset\n",
    "    for var_name in composite:\n",
    "        # Extract the underlying numpy array and append it to the list\n",
    "        arrays.append(composite[var_name].values)\n",
    "\n",
    "    # Stack the numpy arrays along a new axis\n",
    "    combined_array = np.stack(arrays, axis=-1)\n",
    "\n",
    "    # Return the combined numpy array\n",
    "    return combined_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set env variable for google cloud credentials, used behind the scenes by a couple functions\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/Users/adamhunter/Documents/school projs/firenet/data/credentials/firenet-99-writer.json'\n",
    "# Use fsspec to create a file system\n",
    "fs = fsspec.filesystem('gcs', token=os.environ['GOOGLE_APPLICATION_CREDENTIALS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_names = get_blob_names()\n",
    "len(blob_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected_blobs = select_blobs(blob_names)\n",
    "selected_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem('gcs')\n",
    "\n",
    "datasets = get_datasets(selected_blobs, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiband_images = form_multiband_images(datasets)\n",
    "\n",
    "multiband_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hourly_composite = create_hourly_composite(multiband_images)\n",
    "\n",
    "hourly_composite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_array = combine_arrays_from_composite(hourly_composite)\n",
    "\n",
    "# Print the combined array for debugging purposes\n",
    "print(combined_array)\n",
    "\n",
    "# Print the shape of the combined array for debugging purposes\n",
    "print(combined_array.shape)\n",
    "\n",
    "# Print the data type of the combined array for debugging purposes\n",
    "print(combined_array.dtype)\n",
    "\n",
    "# Print the minimum value in the combined array for debugging purposes\n",
    "print(combined_array.min())\n",
    "\n",
    "# Print the maximum value in the combined array for debugging purposes\n",
    "print(combined_array.max())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlitenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
